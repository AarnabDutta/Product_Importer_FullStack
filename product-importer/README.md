# ğŸš€ Product Importer - Full Stack Application

A production-ready full-stack application for importing and managing products from CSV files with real-time progress tracking, built with FastAPI, React, Celery, and PostgreSQL.

[![FastAPI](https://img.shields.io/badge/FastAPI-0.115.5-009688?style=flat&logo=fastapi)](https://fastapi.tiangolo.com)
[![React](https://img.shields.io/badge/React-18.2.0-61DAFB?style=flat&logo=react)](https://reactjs.org)
[![Celery](https://img.shields.io/badge/Celery-5.4.0-37814A?style=flat&logo=celery)](https://docs.celeryproject.org)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-Supabase-336791?style=flat&logo=postgresql)](https://www.postgresql.org)

## âœ¨ Features

### ğŸ¯ Core Functionality
- **Bulk CSV Import** - Import thousands of products efficiently with optimized batch processing (10,000 rows/batch)
- **Real-time Progress Tracking** - Server-Sent Events (SSE) for live upload and processing status updates
- **Duplicate Handling** - Automatic upsert logic using PostgreSQL `ON CONFLICT DO UPDATE`
- **Full CRUD Operations** - Create, read, update, and delete products with advanced filtering
- **Webhook Management** - Configure and test webhooks for product events
- **Background Processing** - Celery workers handle CSV processing asynchronously

### ğŸ¨ User Experience
- **Modern UI** - Beautiful gradient animations and smooth transitions
- **Real-time Feedback** - Progress bars with percentage and row count updates
- **Advanced Filtering** - Filter products by SKU, name, description, and status
- **Pagination** - Efficient data loading with customizable page sizes (25/50/100)
- **Responsive Design** - Mobile-friendly interface with adaptive layouts
- **Error Handling** - User-friendly error messages and validation

### âš¡ Performance Optimizations
- **Optimized CSV Processing** - 5-10x faster than basic implementations
- **Connection Pooling** - PostgreSQL connection pool (10 base + 20 overflow)
- **Efficient Data Conversion** - Uses pandas `to_dict('records')` instead of `iterrows()`
- **Batch Timestamps** - Calculate timestamps once per batch instead of per row
- **Reduced Progress Updates** - Update every 2 chunks instead of every row

## ğŸ“ Project Structure

```
product-importer/
â”œâ”€â”€ backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/                      # API Endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ products.py           # Product CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py             # CSV upload endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ progress.py           # SSE progress streaming
â”‚   â”‚   â”‚   â””â”€â”€ webhooks.py           # Webhook management
â”‚   â”‚   â”œâ”€â”€ tasks/                    # Celery Tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py         # Celery configuration
â”‚   â”‚   â”‚   â””â”€â”€ import_tasks.py       # CSV import task (optimized)
â”‚   â”‚   â”œâ”€â”€ utils/                    # Utility Functions
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ csv_processor.py      # CSV validation & processing
â”‚   â”‚   â”‚   â””â”€â”€ webhook_trigger.py    # Webhook execution
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                 # Settings & environment variables
â”‚   â”‚   â”œâ”€â”€ database.py               # SQLAlchemy setup
â”‚   â”‚   â”œâ”€â”€ models.py                 # Database models
â”‚   â”‚   â”œâ”€â”€ schemas.py                # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ crud.py                   # Database operations
â”‚   â”‚   â””â”€â”€ main.py                   # FastAPI app initialization
â”‚   â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚   â”œâ”€â”€ .env.example                  # Environment variables template
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ frontend/                         # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/               # React Components
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.jsx        # CSV upload with progress
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductList.jsx       # Product table & pagination
â”‚   â”‚   â”‚   â”œâ”€â”€ ProductForm.jsx       # Create/Edit modal
â”‚   â”‚   â”‚   â”œâ”€â”€ WebhookManager.jsx    # Webhook configuration
â”‚   â”‚   â”‚   â””â”€â”€ ConfirmDialog.jsx     # Reusable confirmation modal
â”‚   â”‚   â”œâ”€â”€ services/                 # API Services
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js                # Axios HTTP client
â”‚   â”‚   â”‚   â””â”€â”€ sse.js                # SSE connection handler
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ App.css               # Animated CSS styles
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Main app component
â”‚   â”‚   â””â”€â”€ index.jsx                 # React entry point
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ index.html
â”‚   â”œâ”€â”€ package.json                  # Node dependencies
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docker-compose.yml                # Redis for local development
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md                         # This file
```

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - High-performance Python web framework
- **SQLAlchemy** - ORM for database operations
- **PostgreSQL** - Primary database (Supabase hosted)
- **Celery** - Distributed task queue for background jobs
- **Redis** - Message broker for Celery & result backend
- **Pandas** - CSV processing and data manipulation
- **SSE-Starlette** - Server-Sent Events support
- **Pydantic** - Data validation and settings management

### Frontend
- **React 18** - Modern UI library with hooks
- **Axios** - HTTP client for API requests
- **EventSource API** - Native SSE support for real-time updates
- **CSS3** - Advanced animations and gradients

### Infrastructure
- **Supabase** - Managed PostgreSQL database
- **Railway/Render** - Deployment platform (recommended)
- **Docker** - Containerization for Redis

## ğŸ“‹ Prerequisites

- Python 3.9+
- Node.js 16+
- PostgreSQL (Supabase account)
- Redis (via Docker or Windows service)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/AarnabDutta/Product_Importer_FullStack.git
cd product-importer
```

### 2. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate

# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
```

**Edit `.env` with your configuration:**
```env
DATABASE_URL=postgresql://user:password@host:port/database
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0
UPLOAD_DIR=./uploads
MAX_UPLOAD_SIZE=524288000
CHUNK_SIZE=10000
```

### 3. Start Redis

**Option A: Using Docker** (Recommended)
```bash
docker-compose up -d
```

**Option B: Using Windows Service**
```bash
# Redis should be running as a service
# Check status:
redis-cli ping
# Expected response: PONG
```

### 4. Start Backend Services

**Terminal 1 - FastAPI Server:**
```bash
cd backend
venv\Scripts\activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Celery Worker:**
```bash
cd backend
venv\Scripts\activate
celery -A app.tasks.celery_app worker --loglevel=info --pool=solo
```

Backend will be available at `http://localhost:8000`

API Documentation: `http://localhost:8000/docs`

### 5. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend will be available at `http://localhost:3000`

## ğŸ“Š Database Schema

### Products Table
```sql
CREATE TABLE products (
  id SERIAL PRIMARY KEY,
  sku VARCHAR(100) UNIQUE NOT NULL,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  active BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  INDEX ix_products_sku_lower (LOWER(sku))
);
```

### Webhooks Table
```sql
CREATE TABLE webhooks (
  id SERIAL PRIMARY KEY,
  url VARCHAR(500) NOT NULL,
  event_type VARCHAR(50) NOT NULL,
  enabled BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ”Œ API Endpoints

### Products
- `GET /api/products` - List products with pagination & filters
- `GET /api/products/{id}` - Get single product
- `POST /api/products` - Create new product
- `PUT /api/products/{id}` - Update product
- `DELETE /api/products/{id}` - Delete product
- `DELETE /api/products` - Delete all products

### Upload
- `POST /api/upload` - Upload CSV file (returns task_id)
- `GET /api/progress/{task_id}` - Stream processing progress (SSE)

### Webhooks
- `GET /api/webhooks` - List webhooks
- `POST /api/webhooks` - Create webhook
- `PUT /api/webhooks/{id}` - Update webhook
- `DELETE /api/webhooks/{id}` - Delete webhook
- `POST /api/webhooks/{id}/test` - Test webhook

### Health
- `GET /` - API status
- `GET /health` - Health check

## ğŸ“ CSV Format

Your CSV file should contain these columns:

| Column | Required | Type | Description |
|--------|----------|------|-------------|
| sku | âœ… Yes | String | Unique product identifier (max 100 chars) |
| name | âœ… Yes | String | Product name (max 255 chars) |
| description | âŒ No | Text | Product description |
| active | âŒ No | Boolean | Product status (defaults to true) |

**Example CSV:**
```
sku,name,description,active
PROD-001,Laptop,High-performance laptop,true
PROD-002,Mouse,Wireless mouse,true
PROD-003,Keyboard,Mechanical keyboard,false
```

## âš™ï¸ Configuration

### Celery Task Settings
Located in `backend/app/tasks/celery_app.py`:

```python
task_serializer='json'
task_track_started=True
task_time_limit=3600           # 1 hour max
task_soft_time_limit=3300      # 55 minutes soft limit
worker_prefetch_multiplier=1
worker_max_tasks_per_child=1000
```

### Import Optimization Settings
Located in `backend/app/tasks/import_tasks.py`:

```python
chunk_size = 10000  # Rows per batch (adjustable)
```

**Recommended settings:**
- **5,000 rows/batch** - Safe default, works on most systems
- **10,000 rows/batch** - Optimal for most use cases (current default)
- **20,000+ rows/batch** - Maximum speed, requires more memory

## ğŸš¢ Deployment

### Railway Deployment

1. **Create Railway Account**: https://railway.app

2. **Add Services:**
   - Backend (FastAPI)
   - Celery Worker
   - Redis Database
   - Frontend (React)

3. **Environment Variables:**

**Backend & Celery Worker:**
```env
DATABASE_URL=<supabase_connection_string>
REDIS_URL=${{Redis.REDIS_URL}}
SECRET_KEY=<generate_random_string>
UPLOAD_DIR=/tmp/uploads
MAX_UPLOAD_SIZE=524288000
CHUNK_SIZE=10000
```

**Frontend:**
```env
REACT_APP_API_URL=<backend_railway_url>
```

4. **Deploy Commands:**

**Backend:**
- Root Directory: `backend`
- Start Command: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`

**Celery Worker:**
- Root Directory: `backend`
- Start Command: `celery -A app.tasks.celery_app worker --loglevel=info --pool=solo`

**Frontend:**
- Root Directory: `frontend`
- Build Command: `npm run build`
- Start Command: `npm run start`

### Docker Deployment (Optional)

**backend/Dockerfile:**
```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ§ª Testing

### Test CSV Upload
```bash
curl -X POST http://localhost:8000/api/upload \
  -F "file=@products.csv"
```

### Monitor Progress
```bash
# Replace {task_id} with the ID from upload response
curl -N http://localhost:8000/api/progress/{task_id}
```

### Check Health
```bash
curl http://localhost:8000/health
```

## ğŸ› Troubleshooting

### Issue: Redis Connection Failed
**Solution:**
```bash
# Check if Redis is running
redis-cli ping

# If not, start Redis
docker-compose up -d

# OR on Windows:
net start Redis
```

### Issue: Celery Worker Not Receiving Tasks
**Solution:**
```bash
# Restart Celery worker
# Stop with Ctrl+C, then:
celery -A app.tasks.celery_app worker --loglevel=info --pool=solo
```

### Issue: CSV Upload Fails with Duplicate SKU Error
**Solution:** The system automatically handles duplicates using upsert. If error persists, check that:
1. Your CSV doesn't have duplicates within the same file
2. The `sku` column has a unique index in the database

### Issue: Progress Bar Not Updating
**Solution:**
1. Check backend logs for SSE errors
2. Verify Celery worker is running
3. Ensure Redis is accessible
4. Check browser console for EventSource errors

## ğŸ“ˆ Performance Metrics

### Import Speed
- **Small files** (< 1,000 rows): ~2-5 seconds
- **Medium files** (10,000 rows): ~10-20 seconds
- **Large files** (100,000 rows): ~2-3 minutes
- **Very large files** (500,000 rows): ~10-15 minutes

### Optimization Results

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| Batch Size | 1,000 | 10,000 | 10x |
| Processing Method | iterrows() | to_dict() | 15x faster |
| Timestamp Generation | Per row | Per batch | 1000x |
| Overall Speed | Baseline | **5-10x faster** | ğŸš€ |

## ğŸ”’ Security Considerations

- Environment variables for sensitive data
- CORS configuration for production
- File size limits (500MB default)
- CSV validation before processing
- SQL injection prevention via SQLAlchemy ORM
- Input sanitization in Pydantic schemas

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

**Aarnab Dutta**
- GitHub: [@AarnabDutta](https://github.com/AarnabDutta)

## ğŸ™ Acknowledgments

- FastAPI for the excellent framework
- Celery for robust task processing
- Supabase for managed PostgreSQL
- Railway for easy deployment
- React team for the amazing UI library

## ğŸ“ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Email: your.email@example.com

---

**Built with â¤ï¸ using FastAPI, React, and Celery**